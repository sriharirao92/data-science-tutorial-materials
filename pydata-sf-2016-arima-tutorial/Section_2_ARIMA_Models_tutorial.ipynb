{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/svds_logo.png\" alt=\"SVDS\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData San Francisco 2016\n",
    "## Applied Time Series Econometrics in Python (and R) Tutorial\n",
    "### Section 2: Exploratory Time Series Data Analysis and the Class of ARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics in this section include \n",
    "\n",
    "- 2.1 The notion of stochastic processes, time series, and stationarity\n",
    "- 2.2 Exploratory Time Series Data Analysis\n",
    "- 2.3 Mathematical formulation of ARIMA models\n",
    "- 2.4 An Introduction to the *Box-Jenkins Approach* to ARIMA Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The notion of Stochastic Processes, Time Series, Stationarity, Autocorrelation\n",
    "<div class=\"alert alert-danger\"> Note: This is a relatively dense section. However, it sets up the necessary framework for us to study the class of *Autoregressive Integrated Moving Average* model. </div>\n",
    "\n",
    "#### Key Takeaway from this section:\n",
    "1. An observed time series is treated as a realization of an underlying probability model.\n",
    "2. We will study a certain class of probability model that comes with a very appealing (and simple) probability structure.\n",
    "3. The concept of (weak) stationarity is a key requirement of the class of time series models that we will study.\n",
    "4. The concept of autocorrelation function and (partial) autocorrelation function are a main tool for us to analyze a time series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $\\textbf{autocovariance function}$ is defined as\n",
    "\n",
    "$$\\gamma_{x}(s,t) = cov(x_s,x_t) = E[(x_s-\\mu_s)(x_t-\\mu_t)] \\forall s,t$$\n",
    "\n",
    "* Two natural implications are $(1) \\gamma_{x}(s,t) = \\gamma_{x}(t,s)$ and $(2)$ $\\gamma_{x}(s,s) = cov(x_s,x_s) = E[(x_s-\\mu_s)^2]$\n",
    "\n",
    "* A correlation of a variable with itself at different times is known as $\\textit{autocorrelation}$. If a time series model is second-order stationary (i.e. stationary in both mean and variance: $\\mu_t = \\mu$ and $\\sigma_t^2 = \\sigma^2$ for all $t$), then an $\\textit{autocovariance function}$ can be expressed as a function only of the time lag $k$:\n",
    "\n",
    "$$ \\gamma_k = E[(x_t-\\mu)(x_{t+k} - \\mu)] $$\n",
    "  \n",
    "* Likewise, the autocorrelation function \\emph{acf} is defined as\n",
    "\n",
    "$$ \\rho_k = \\frac{\\gamma_k}{\\sigma^2} $$\n",
    "  \n",
    "* When $k=0$, $\\rho_0 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation of ($\\mathbf{1^{st}}$ order) Dependency:\n",
    "\n",
    "* Using the $\\textit{moment principles}$, the $\\textit{acvf}$ and $\\textit{acf}$ can be estimated from a time series by their sample equivalents. The sample \\emph{acvf} can be estimated using the following formula:\n",
    "\n",
    "$$ \\hat{\\gamma}_k = \\frac{1}{T} \\sum_{t=1}^{T-k} \\left( x_t - \\bar{x} \\right) \\left( x_{t+k} - \\bar{x} \\right) $$\n",
    "\n",
    "* Note that the sum is divided by $T$ and and not $T-k$.\n",
    "\n",
    "* The sample $\\textit{ACF}$ is defined by\n",
    "\n",
    "$$ \\frac{\\hat{\\gamma}_k}{\\hat{\\gamma}_0} = \\frac{\\frac{1}{T} \\sum_{t=1}^{T-k} \\left( x_t - \\bar{x} \\right) \\left( x_{t+k} - \\bar{x} \\right)}{ \\frac{1}{T} \\sum_{t=1}^{T} \\left( x_t - \\bar{x} \\right)^2} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notion of Stationarity:\n",
    "\n",
    "\n",
    "* A time series ${x_t}$ is said to be $\\textit{strictly stationary}$ if the joint distributions $F(x_{t_1}, \\dots, x_{t_n})$ and $F( x_{t_1+m}, \\dots, x_{t_n +m})$ are the same, $\\forall$ $t_1, ... t_n$ and $m$. This is a very strong condition, too strong to be applied in practice; it implies that the distribution is unchanged for any time shift!\n",
    "\n",
    "* A weaker and more practical stationarity condition is that of $\\textit{weakly stationary}$ (or $\\textit{second order stationarity}$). A time series $x_t$ is said to be $\\textit{weakly stationary}$ if it is mean and variance stationary and its autocovariance $Cov(x_t,x_{t+k})$ depends only the time displacement $k$ and can be written as $\\gamma(k)$. \n",
    "\n",
    "* Second order stationarity plays an important role in many of the time series models we will discuss in this tutorial; if a time series is second order stationary, then once a distribution assumption, such as normality, is imposed, the series can be completely characterized by its mean and covariance structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exploratory Time Series Data Analysis\n",
    "\n",
    "* Now that we introduce the essential concepts for characterizing the probability structure of a time series, we will proceed to \"$\\textit{explore}$\" these characteristics empirically.\n",
    "\n",
    "* Specifically, we will use *time series plot, histogram (and its variants), plot of sample autocorrelation, and plot of sample partial autocorrelation}* to examine a given time series. \n",
    "\n",
    "* These visuals play a very crucial role in the $\\textit{Box-Jenkins approach}$ to ARIMA modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you get an error in reading pandas-datareader run the following\n",
    "# !conda install pandas-datareader -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # Remote Data Access\n",
    "# import pandas_datareader.data as web\n",
    "# import datetime\n",
    "# # reference: https://pandas-datareader.readthedocs.io/en/latest/remote_data.html\n",
    "\n",
    "# TSA from Statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# Display and Plotting\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # pandas\n",
    "np.set_printoptions(precision=5, suppress=True) # numpy\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# seaborn plotting style\n",
    "sns.set(style='ticks', context='poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data from the internet using the Remote Data Reader\n",
    "# This is a very useful function, as it allows one to access a lot of time series and (non-time series) data publicly\n",
    "# available on the internet\n",
    "\n",
    "# start = pd.Timestamp('2000-01-01')\n",
    "# end = pd.Timestamp('2016-07-31')\n",
    "\n",
    "# C = web.DataReader(\"C\", 'yahoo', start, end)\n",
    "# Sentiment= web.DataReader(\"UMCSENT\", 'fred', start, end)\n",
    "# T10yr = web.DataReader(\"^TNX\", 'yahoo', start, end)\n",
    "\n",
    "# Save the DataFrame to a csv file\n",
    "# Sentiment.to_csv('data/sentiment.csv')\n",
    "# C.to_csv('data/citi.csv')\n",
    "# T10yr.to_csv('data/T10yr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the data\n",
    "\n",
    "Sentiment = 'data/sentiment.csv'\n",
    "Sentiment = pd.read_csv(Sentiment, index_col=0, parse_dates=[0])\n",
    "\n",
    "C = 'data/citi.csv'\n",
    "C = pd.read_csv(C, index_col=0, parse_dates=[0])\n",
    "\n",
    "T10yr = 'data/T10yr.csv'\n",
    "T10yr = pd.read_csv(T10yr, index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Citigroup's stock price:\", \"\\n\", C.dtypes, \"\\n\")\n",
    "print(\"10 Year Treasury Bond Rate:\", \"\\n\", T10yr.dtypes, \"\\n\")\n",
    "print(\"University of Michigan: Consumer Sentiment:\", \"\\n\", Sentiment.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T10yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C['Close'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C.close = C['Close']\n",
    "T10yr.close = T10yr['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots to used in Exploratory  Time Series Analysis\n",
    "\n",
    "* Time series plot: to visualize the dynamic and evolution of the series\n",
    "* Histogram or NP Density: to visualize the distribution \n",
    "* Sample ACF and PACF graphs: to examine autocorrelation and partial autocorrelation\n",
    "* Scatterplot matrix on lags: an alternative way to visualize autocorrelation of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the series from 2005 - 2016\n",
    "sentiment_short = Sentiment.ix['2005':'2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_short.index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sentiment_short.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_short.plot(figsize=(12,8))\n",
    "plt.legend(bbox_to_anchor=(1.25, 0.5))\n",
    "plt.title(\"Consumer Sentiment\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(sentiment_short, lags=20, ax=ax1)\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "fig.tight_layout();\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(sentiment_short, lags=20, ax=ax2)\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatterplot matrix is another way to visualize the autocorrelation\n",
    "# Its advantage is that it is very intuitive, as scatterplot (i.e. one of the plots in a scatterplot matrix) \n",
    "# is used often in practice\n",
    "\n",
    "lags=9\n",
    "\n",
    "ncols=3\n",
    "nrows=int(np.ceil(lags/ncols))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(4*ncols, 4*nrows))\n",
    "\n",
    "for ax, lag in zip(axes.flat, np.arange(1,lags+1, 1)):\n",
    "    lag_str = 't-{}'.format(lag)\n",
    "    X = (pd.concat([sentiment_short, sentiment_short.shift(-lag)], axis=1,\n",
    "                   keys=['y'] + [lag_str]).dropna())\n",
    "\n",
    "    X.plot(ax=ax, kind='scatter', y='y', x=lag_str);\n",
    "    corr = X.corr().as_matrix()[0][1]\n",
    "    ax.set_ylabel('Original')\n",
    "    ax.set_title('Lag: {} (corr={:.2f})'.format(lag_str, corr));\n",
    "    ax.set_aspect('equal');\n",
    "    sns.despine();\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Or, we can plot the four essential plots all at once:\n",
    "\n",
    "def tsplot(y, lags=None, title='', figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Original source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsplot(sentiment_short, title='Consumer Sentiment', lags=36);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mathematical formulation of ARIMA models\n",
    "\n",
    "* A time series ${z_t}$ follows an ARIMA$(p,d,q)$ process if the $d^{th}$ differences of the ${z_t}$ series is an ARMA($p,q$) process. Using lag operator, it can expressed as \n",
    "\n",
    "$$\\begin{equation}\n",
    "  \\phi_p(B)(1-B)^d z_t = \\theta_q(B) \\omega_t\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\phi_p$ and $\\theta_q$ are polynomials of orders $p$ and $q$.\n",
    "\n",
    "* Writing an ARIMA$(p,d,q)$ may seem too abstract, and whenever a model is presented this way, you may get a feel of the model by making simple cases, such as a low order ARIMA$(p,d,q)$ model. \n",
    "\n",
    "\n",
    "\n",
    "* Below show two such examples to unpack some of these notations:\n",
    "\n",
    "$\\textbf{Example 1:}$\n",
    "Consider the model $ z_t = z_{t-1} + \\omega_t + \\theta \\omega_{t-1}$.  Re-write this model using lag (or backward shift) operator. By now, we should be familiar with this kind of manipulation:\n",
    "\n",
    "$$\\begin{align}\n",
    "   z_t &= z_{t-1} + \\omega_t + \\theta \\omega_{t-1} \\\\\n",
    "   z_t - z_{t-1} &= \\omega_t + \\theta \\omega_{t-1} \\\\\n",
    "  (1-B)z_t &= (1+\\theta B)\\omega_t\n",
    "\\end{align}$$\n",
    "\n",
    "where $B$ is a lag operator that when applying to $z_t$, gives $z_{t-1}$. That is, $Bz_t = z_{t-1}$.\n",
    "\n",
    "* This becomes an ARIMA(0,1,1) model, or $\\textit{integrated moving average}$ model (IMA(1,1)).\n",
    "\n",
    "$\\textbf{Example 2:}$\n",
    "Consider a model of the form\n",
    "\n",
    "$$\\begin{equation}\n",
    "     z_t = \\phi z_{t-1} + z_{t-1} - \\phi z_{t-2} + \\omega_t\n",
    "\\end{equation}$$\n",
    "\n",
    "* Rewrite the equation, re-arrange terms, and factorize them:\n",
    "\n",
    "$$\\begin{align}\n",
    "   z_t - z_{t-1} &= \\phi (z_{t-1} - z_{t-2}) + \\omega_t \\\\\n",
    "   (z_t - z_{t-1}) - \\phi (z_{t-1} - z_{t-2}) &= \\omega_t \\\\\n",
    "   (1 - \\phi B)(z_t - z_{t-1}) &=  \\omega_t \\\\\n",
    "   (1 - \\phi B) \\bigtriangledown z_t &=  \\omega_t \\\\\n",
    "   (1 - \\phi B)(1 - B)z_t  &= \\omega_t\n",
    "\\end{align}$$\n",
    "\n",
    "The model can be re-written as $(1 - \\phi B) \\bigtriangledown y_t  = \\omega_t$, which is an ARIMA(1,1,0) model.\n",
    "\n",
    "**Sidenotes**\n",
    "\n",
    "A series ${z_t}$ is $\\textit{integrated}$ of order $d$, denoted as $I(d)$, if the $d^{th}$ differences of ${z_t}$ is a white noise: $\\bigtriangledown^d y_t = \\omega_t$, where $\\bigtriangledown^d \\equiv (1-B)^d$:\n",
    "\n",
    "$$\\begin{equation}\n",
    "  (1-B)^d y_t = \\omega_t\n",
    "\\end{equation}$$\n",
    "\n",
    "As such, random walk is the special case I(1).\n",
    "\n",
    "* In practice, I(0) and I(1) cases find themselves having the most applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 An Overview of the Box-Jenkins Approach to Non-Seasonal ARIMA Modeling\n",
    "\n",
    "1. Assess the stationarity of the process $z_t$\n",
    "2. If the process is not stationary, difference it (i.e. create an integrated model) as many times as needed to produced a stationary process to be modeled using the $\\textit{mixed autoregressive-moving average process}$ described above.\n",
    "3. Identify (i.e. determining the order of the process) the resulting the ARMA model.\n",
    "  * The sample autocorrelation and sample partial autocorrelation functions are tools used in step $1$ and $2$.\n",
    "\n",
    "In practice, other steps are necessary in order to produce a functionable model. These steps include:\n",
    "- Model diagnostic checking\n",
    "- Re-specification of the model if one or more of the underlying statistical assumptions is not satisfied\n",
    "- Model selection\n",
    "- Perform statistical inference and/or forecasting\n",
    "- Forecast evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "**Exercise 2:**\n",
    "\n",
    "Let use *series1.csv* and conduct the exploratory data analysis \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import the csv file containing the series for the analysis\n",
    "filename_ts = 'data/series1.csv'\n",
    "ts_df = pd.read_csv(filename_ts, index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2: Explore the patterns of the time series and its autocorrelation and partial autocorrelation structure\n",
    "\n",
    "# Choose the number of lags to display the sample ACF and PACF\n",
    "n_lag=25\n",
    "graph_title=\"Series 1\"\n",
    "\n",
    "# Make sure the tsplot() function is defined before running the following command\n",
    "tsplot(ts_df, title=graph_title, lags=n_lag);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 3**\n",
    "Type your observations here and discuss with your neighbors.\n",
    "* Are there any trend, seasonality, cycles?\n",
    "* What are pattern of the ACF? Does it decline exponentially or dampen towards zero? Does it have a sharp cut-off?\n",
    "* What about the PACF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
